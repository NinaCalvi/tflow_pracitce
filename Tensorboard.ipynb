{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Tensorboard Basics\n",
    "\n",
    "Following tutorial from https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/4_Utils/tensorboard_advanced.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nina/Documents/Streamba/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#import mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = '/logs/tensorboard_basics/'\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer n. of features\n",
    "n_hidden_2 = 256 # 2nd layer n. of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: assemble your graph\n",
    "\n",
    "1. Import data (either with tf.data or with placeholders)\n",
    "2. Define the weights\n",
    "3. Define the inference model\n",
    "4. Define loss function\n",
    "5. Define optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**placeholders**: variable to which data will be assigned later on. Allows for building graphs without having the data.\n",
    "\n",
    "```placehoder(type, shape, name)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "# mnist data image of shape 28*28=784\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
    "# 0-9 digits recognition => 10 classes\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='LabelData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the model (step 3)\n",
    "\n",
    "try making it as pythonic as possible. Good modularity\n",
    "\n",
    "Create a basic multilayer perceptron with 2 hidden layers and relu activation funciton.\n",
    "\n",
    "**tf.summary**: way to condense information that can then be visualised in the Tensorboard. Summaries can be saved to file using **_tf.summary.FileWriter( some-directory, sess.graph)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='W1'),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='W2'),\n",
    "    'w3': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='W3')\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='b1'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='b2'),\n",
    "    'b3': tf.Variable(tf.random_normal([n_classes]), name='b3')\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1']) \n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Create a summary to visualize the first layer ReLU activation\n",
    "    tf.summary.histogram(\"relu1\", layer_1) #summary ops\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Create another summary to visualize the second layer ReLU activation\n",
    "    tf.summary.histogram(\"relu2\", layer_2)\n",
    "    # Output layer\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    return out_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAME SHARING**: groups ops into *scopes*. Aids with visualizing in tensorboard\n",
    "\n",
    "Also follow by defining **loss** and **optimization** functions (steps 4 and 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Model'):\n",
    "    percep = multilayer_perceptron(x, weights, biases)\n",
    "    \n",
    "with tf.name_scope('Loss'):\n",
    "    #create loss function\n",
    "    #softmax cross entropy\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=percep, labels=y))\n",
    "\n",
    "with tf.name_scope('Optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    \n",
    "    # Op to calculate variable gradient\n",
    "    grads = optimizer.compute_gradients(loss, tf.trainable_variables())\n",
    "    \n",
    "    #create optimizer - STOCHASTIC GRADIENT DESCENT\n",
    "    apply_grads = optimizer.apply_gradients(grads_and_vars=grads)\n",
    "\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc = tf.equal(tf.argmax(percep, 1), tf.argmax(y,1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: execute the computation - which is basically training your model. \n",
    "\n",
    "1. Initialize all model variables for the first time.\n",
    "2. Initialize iterator / feed in the training data.\n",
    "3. Execute the inference model on the training data, so it calculates for each training input example the output with the current model parameters.\n",
    "4. Compute the cost\n",
    "5. Adjust the model parameters to minimize/maximize the cost depending on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'Optimizer/gradients/Model/MatMul_grad/tuple/control_dependency_1:0' shape=(784, 256) dtype=float32>,\n",
       "  <tf.Variable 'W1:0' shape=(784, 256) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Optimizer/gradients/Model/MatMul_1_grad/tuple/control_dependency_1:0' shape=(256, 256) dtype=float32>,\n",
       "  <tf.Variable 'W2:0' shape=(256, 256) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Optimizer/gradients/Model/MatMul_2_grad/tuple/control_dependency_1:0' shape=(256, 10) dtype=float32>,\n",
       "  <tf.Variable 'W3:0' shape=(256, 10) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Optimizer/gradients/Model/Add_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,\n",
       "  <tf.Variable 'b1:0' shape=(256,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Optimizer/gradients/Model/Add_1_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>,\n",
       "  <tf.Variable 'b2:0' shape=(256,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Optimizer/gradients/Model/Add_2_grad/tuple/control_dependency_1:0' shape=(10,) dtype=float32>,\n",
       "  <tf.Variable 'b3:0' shape=(10,) dtype=float32_ref>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name W1:0 is illegal; using W1_0 instead.\n",
      "INFO:tensorflow:Summary name W2:0 is illegal; using W2_0 instead.\n",
      "INFO:tensorflow:Summary name W3:0 is illegal; using W3_0 instead.\n",
      "INFO:tensorflow:Summary name b1:0 is illegal; using b1_0 instead.\n",
      "INFO:tensorflow:Summary name b2:0 is illegal; using b2_0 instead.\n",
      "INFO:tensorflow:Summary name b3:0 is illegal; using b3_0 instead.\n",
      "INFO:tensorflow:Summary name W1:0/gradient is illegal; using W1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name W2:0/gradient is illegal; using W2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name W3:0/gradient is illegal; using W3_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b1:0/gradient is illegal; using b1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b2:0/gradient is illegal; using b2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b3:0/gradient is illegal; using b3_0/gradient instead.\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#monitor loss and accuracy\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('acc', acc)\n",
    "\n",
    "#create summary to visualize weights\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var)\n",
    "\n",
    "    \n",
    "#create summaries to visualize gradients\n",
    "for grad, var in grads:\n",
    "    tf.summary.histogram(var.name + '/gradient', grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to simplify and manage all the summaries it is easier to merge all summaries together\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.summary.FileWriter**: op that writes summaries to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #run initializer\n",
    "    #always initialize the vairables first\n",
    "    sess.run(init)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
